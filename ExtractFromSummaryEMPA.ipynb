{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2TKv+KjlyWAVxwBBCS1KM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mzucali/pyMinColab/blob/main/ExtractFromSummaryEMPA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LEGGE IL FILE SUMMARY.TXT ed estrae DL e SD:\n",
        "\n",
        "=>>input il file summary.txt o qualunque altro nome MA .TXT\n",
        "- start Marzo 2023\n",
        "- aggiornamento Novembre 2023"
      ],
      "metadata": {
        "id": "ahx7kYpNKhAu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load and read summary file from EMPA\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "metadata": {
        "id": "xmO9WzXojvoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_elements = input(\"QUANTI ELEMENTI ANALIZZATI? \")\n",
        "#num_elements = 11\n",
        "loop = int(num_elements)+2"
      ],
      "metadata": {
        "id": "FUPCtud4kAOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Separate block"
      ],
      "metadata": {
        "id": "OWVdm5HcotTE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "#file_path = './4-4-23.txt'  # Replace with the actual file path\n",
        "#file_name = file_path.replace(\"./\", \"\")\n",
        "file_path = fn\n",
        "file_name = file_path.replace(\".txt\", \"\")\n",
        "\n",
        "# Initialize variables\n",
        "sections = []\n",
        "current_section = []\n",
        "\n",
        "# Read the file line by line\n",
        "with open(file_path, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "# Identify and extract sections\n",
        "for line in lines:\n",
        "    if re.match(r'^Unknown Specimen', line):\n",
        "        print(\"match: \", line)\n",
        "        # Start of a new section\n",
        "        if current_section:\n",
        "            # Save the current section\n",
        "            sections.append(current_section)\n",
        "            current_section = []\n",
        "    # Add line to the current section\n",
        "    current_section.append(line.strip())\n",
        "\n",
        "# Save the last section\n",
        "if current_section:\n",
        "    sections.append(current_section)\n",
        "\n",
        "# Process each section\n",
        "for section_content in sections:\n",
        "    # Find the start and end indices for the desired block\n",
        "    start_index = next((i for i, line in enumerate(section_content) if line.startswith('Element\\tPeak(mm)')), None)\n",
        "    end_index = next((i for i, line in enumerate(section_content) if line.startswith('Element\\tf(chi)')), None)\n",
        "    print(\"start =\", start_index)\n",
        "    print(\"end =\", end_index)\n",
        "    # Check if both start and end indices are found\n",
        "    if start_index is not None and end_index is not None and end_index > start_index:\n",
        "        # Extract the desired block\n",
        "        block_content = section_content[start_index:end_index]\n",
        "\n",
        "        # Extract the header dynamically from the second line\n",
        "        header = block_content[0].split('\\t')\n",
        "        header.insert(0, \"ID\")\n",
        "\n",
        "        try:\n",
        "            # Create a DataFrame for the current block\n",
        "            df = pd.DataFrame([re.split(r'\\s+', line.strip()) for line in block_content[2:]], columns=header)\n",
        "\n",
        "            # Print or further process the DataFrame\n",
        "            print(df)\n",
        "        except ValueError as e:\n",
        "            print(\"ValueError:\", e)\n",
        "            print(\"Header:\", header)\n",
        "            print(\"Block content:\", block_content)\n",
        "    else:\n",
        "        print(\"Start or end index not found or invalid in the section.\")"
      ],
      "metadata": {
        "id": "-A115OB7ou76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) S.D. extract"
      ],
      "metadata": {
        "id": "-b6On-2Ko2YJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "#file_path = './test2.txt'  # Replace with the actual file path\n",
        "\n",
        "# Initialize variables\n",
        "sections = []\n",
        "current_section = []\n",
        "current_comment = None  # Variable to store the value in Comment line\n",
        "\n",
        "# Read the file line by line\n",
        "with open(file_path, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "# Identify and extract sections\n",
        "for line in lines:\n",
        "    if re.match(r'^Unknown Specimen', line):\n",
        "        print(\"match: \", line)\n",
        "        # Start of a new section\n",
        "        if current_section:\n",
        "            # Save the current section\n",
        "            sections.append((current_comment, current_section))\n",
        "            current_section = []\n",
        "    # Add line to the current section\n",
        "    current_section.append(line.strip())\n",
        "    if line:\n",
        "        try:\n",
        "            line = line.split(\"\\t\")\n",
        "            #print(\"line \",line)\n",
        "            if(line[2] == \"Comment :\"):\n",
        "                #print(\"line_s[2]\",line_s[2])\n",
        "                # Keep track of the comment value\n",
        "                current_comment= line[3]\n",
        "                # Just a spacing line\n",
        "                print(\"comm\",current_comment)\n",
        "        except IndexError:\n",
        "            #print(\"no comm\")\n",
        "            pass\n",
        "\n",
        "# Save the last section\n",
        "if current_section:\n",
        "    sections.append((current_comment, current_section))\n",
        "\n",
        "# Initialize a dictionary to store lists of S.D.(%) values for each element\n",
        "sd_values = {}\n",
        "# Initialize a list to store Comment values\n",
        "comment_list = []\n",
        "\n",
        "# Process each section\n",
        "for comment, section_content in sections:\n",
        "    # Find the start and end indices for the desired block\n",
        "    start_index = next((i for i, line in enumerate(section_content) if line.startswith('Element\\tPeak(mm)')), None)\n",
        "    end_index = next((i for i, line in enumerate(section_content) if line.startswith('Element\\tf(chi)')), None)\n",
        "    print(\"start =\", start_index)\n",
        "    print(\"end =\", end_index)\n",
        "    # Check if both start and end indices are found\n",
        "    if start_index is not None and end_index is not None and end_index > start_index:\n",
        "        # Extract the desired block\n",
        "        block_content = section_content[start_index:end_index]\n",
        "\n",
        "        # Extract the header dynamically from the second line\n",
        "        header = block_content[0].split('\\t')\n",
        "        header.insert(0, \"ID\")\n",
        "\n",
        "        try:\n",
        "            # Create a DataFrame for the current block\n",
        "            df = pd.DataFrame([re.split(r'\\s+', line.strip()) for line in block_content[1:]], columns=header)\n",
        "\n",
        "            # Extract S.D.(%) values for each element in the current block\n",
        "            sd_column_values = df.set_index('Element')['S.D.(%)'].to_dict()\n",
        "\n",
        "            # Update the sd_values dictionary with S.D.(%) values for the current block\n",
        "            for element, sd_value in sd_column_values.items():\n",
        "                sd_values.setdefault(element, []).append(sd_value)\n",
        "\n",
        "            # Print or further process the DataFrame\n",
        "            print(df)\n",
        "        except ValueError as e:\n",
        "            print(\"ValueError:\", e)\n",
        "            print(\"Header:\", header)\n",
        "            print(\"Block content:\", block_content)\n",
        "        # Add Comment value to the list\n",
        "        comment_list.append(comment)\n",
        "    else:\n",
        "        print(\"Start or end index not found or invalid in the section.\")\n",
        "\n",
        "# Print the extracted lists of S.D.(%) values for each element\n",
        "print(\"S.D.(%) values:\")\n",
        "for element, sd_value_list in sd_values.items():\n",
        "    print(f\"{element}: {sd_value_list}\")"
      ],
      "metadata": {
        "id": "1Wk7p6Aoo6PA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) S.D. save"
      ],
      "metadata": {
        "id": "s2k3ooa6o_J3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"S.D.(%) values:\")\n",
        "print(sd_values)\n",
        "for element, sd_value in sd_values.items():\n",
        "\n",
        "    print(f\"{element}: {sd_value}\")\n",
        "\n",
        "output_sd_file_path = file_name+'SD.txt'\n",
        "df_sd = pd.DataFrame.from_dict(sd_values)\n",
        "df_sd.insert(0, 'Comment', comment_list)  # Insert the Comment column at the beginning\n",
        "df_sd.to_csv(output_sd_file_path, index=False, sep='\\t')\n",
        "print(f'S.D. values saved to {output_sd_file_path}')"
      ],
      "metadata": {
        "id": "g-PZJ3cgpGS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) D.L. extract"
      ],
      "metadata": {
        "id": "6nkkVKYbpJzp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "#file_path = './test2.txt'  # Replace with the actual file path\n",
        "\n",
        "# Initialize variables\n",
        "sections = []\n",
        "current_section = []\n",
        "current_comment = None  # Variable to store the value in Comment line\n",
        "\n",
        "# Read the file line by line\n",
        "with open(file_path, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "# Identify and extract sections\n",
        "for line in lines:\n",
        "    if re.match(r'^Unknown Specimen', line):\n",
        "        print(\"match: \", line)\n",
        "        # Start of a new section\n",
        "        if current_section:\n",
        "            # Save the current section\n",
        "            sections.append((current_comment, current_section))\n",
        "            current_section = []\n",
        "    # Add line to the current section\n",
        "    current_section.append(line.strip())\n",
        "    if line:\n",
        "        try:\n",
        "            line = line.split(\"\\t\")\n",
        "            #print(\"line \",line)\n",
        "            if(line[2] == \"Comment :\"):\n",
        "                #print(\"line_s[2]\",line_s[2])\n",
        "                # Keep track of the comment value\n",
        "                current_comment= line[3]\n",
        "                # Just a spacing line\n",
        "                print(\"comm\",current_comment)\n",
        "        except IndexError:\n",
        "            #print(\"no comm\")\n",
        "            pass\n",
        "\n",
        "# Save the last section\n",
        "if current_section:\n",
        "    sections.append((current_comment, current_section))\n",
        "\n",
        "# Initialize a dictionary to store lists of D.L. values for each element\n",
        "dl_values = {}\n",
        "# Initialize a list to store Comment values\n",
        "comment_list = []\n",
        "\n",
        "# Process each section\n",
        "for comment, section_content in sections:\n",
        "    # Find the start and end indices for the desired block\n",
        "    start_index = next((i for i, line in enumerate(section_content) if line.startswith('Element\\tPeak(mm)')), None)\n",
        "    end_index = next((i for i, line in enumerate(section_content) if line.startswith('Element\\tf(chi)')), None)\n",
        "    print(\"start =\", start_index)\n",
        "    print(\"end =\", end_index)\n",
        "    # Check if both start and end indices are found\n",
        "    if start_index is not None and end_index is not None and end_index > start_index:\n",
        "        # Extract the desired block\n",
        "        block_content = section_content[start_index:end_index]\n",
        "\n",
        "        # Extract the header dynamically from the second line\n",
        "        header = block_content[0].split('\\t')\n",
        "        header.insert(0, \"ID\")\n",
        "\n",
        "        try:\n",
        "            # Create a DataFrame for the current block\n",
        "            df = pd.DataFrame([re.split(r'\\s+', line.strip()) for line in block_content[1:]], columns=header)\n",
        "\n",
        "            # Extract S.D.(%) values for each element in the current block\n",
        "            dl_column_values = df.set_index('Element')['D.L.(ppm)'].to_dict()\n",
        "\n",
        "            # Update the dl_values dictionary with D.L.(ppm) values for the current block\n",
        "            for element, dl_value in dl_column_values.items():\n",
        "                dl_values.setdefault(element, []).append(dl_value)\n",
        "\n",
        "            # Print or further process the DataFrame\n",
        "            print(df)\n",
        "        except ValueError as e:\n",
        "            print(\"ValueError:\", e)\n",
        "            print(\"Header:\", header)\n",
        "            print(\"Block content:\", block_content)\n",
        "        # Add Comment value to the list\n",
        "        comment_list.append(comment)\n",
        "    else:\n",
        "        print(\"Start or end index not found or invalid in the section.\")\n",
        "\n",
        "# Print the extracted lists of S.D.(%) values for each element\n",
        "print(\"D.L.(ppm) values:\")\n",
        "for element, dl_value_list in dl_values.items():\n",
        "    print(f\"{element}: {dl_value_list}\")"
      ],
      "metadata": {
        "id": "LbN5ut3UpOH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5) D.L. save file"
      ],
      "metadata": {
        "id": "2AaJc0NepCz9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"D.L. values:\")\n",
        "print(dl_values)\n",
        "for element, dl_value in dl_values.items():\n",
        "\n",
        "    print(f\"{element}: {dl_value}\")\n",
        "\n",
        "output_dl_file_path = file_name+'DL.txt'\n",
        "df_dl = pd.DataFrame.from_dict(dl_values)\n",
        "df_dl.insert(0, 'Comment', comment_list)  # Insert the Comment column at the beginning\n",
        "df_dl.to_csv(output_dl_file_path, index=False, sep='\\t')\n",
        "print(f'D.L. values saved to {output_dl_file_path}')"
      ],
      "metadata": {
        "id": "syrWpYdPpY1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3c1vdEA6pbwH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "OLD"
      ],
      "metadata": {
        "id": "10yiS2ljpCe3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "OLD"
      ],
      "metadata": {
        "id": "r4EiJUAppCcF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Estrazione SD OLD version"
      ],
      "metadata": {
        "id": "z3B2NvZFyOVW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Tue Mar 14 11:30:45 2023\n",
        "GRAZIE ALESSANDRO COMUNIAN\n",
        "@author: alex\n",
        "\"\"\"\n",
        "\n",
        "#file_in = open(\"summary.txt\", \"r\")\n",
        "file_in = open(fn,\"r\")\n",
        "outFile = open(\"result2_tmpSD.txt\", \"w\")\n",
        "\n",
        "lines = file_in.readlines()\n",
        "\n",
        "for i, line in enumerate(lines):\n",
        "    # Just a spacing line\n",
        "    #line_sp = line.split()\n",
        "    #print(line_sp)\n",
        "    line_s = line.split(\"\\t\")\n",
        "    #print(line_s)\n",
        "    if line_s:\n",
        "        try:\n",
        "            if(line_s[2] == \"Comment :\"):\n",
        "                #print(\"line_s[2]\",line_s[2])\n",
        "                # Keep track of the comment value\n",
        "                comm = line_s[3]\n",
        "                # Just a spacing line\n",
        "                #print(\"comm\",comm)\n",
        "        except IndexError:\n",
        "            pass\n",
        "\n",
        "        if(line_s[0] == \"Curr.(A) :\"):\n",
        "#        if(line_s[0] == \"Element\t\"):\n",
        "            #print(\"ID {0} Comment\".format(lines[i+1][:-1]))\n",
        "            outFile.write(\"ID {0} Comment\\n\".format(lines[i+1][:-1]))\n",
        "            for j in range(2,loop):\n",
        "                #print(\"{0} {1}\\n\".format(lines[i+j][:-1], comm), end=\"\")\n",
        "                outFile.write(\"{0} {1}\\n\".format(lines[i+j][:-1], comm))\n",
        "                #outFile.write(\" {0}\\n\".format(lines))\n",
        "\n",
        "file_in.close()\n",
        "outFile.close() #result2.txt\n",
        "\n",
        "print(\"completed SD extraction\")"
      ],
      "metadata": {
        "id": "Sh1_nZ_vPbNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove spaces SD"
      ],
      "metadata": {
        "id": "5oBvlav1-F9O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#RESULT3 con spazi e tab corretti SD\n",
        "newopen = open(\"result2_final_tmpSD.txt\", \"w\")\n",
        "with open(\"result2_tmpSD.txt\") as f:\n",
        "  first_line = f.readline()\n",
        "  first_line_split = first_line.split()\n",
        "  first_line = '\\t'.join(first_line_split)+'\\n'\n",
        "  newopen.write(first_line)\n",
        "  #print(first_line)\n",
        "\n",
        "with open(\"result2_tmpSD.txt\") as f:\n",
        "  for line in f:\n",
        "    if 'ID Element\tPeak(mm)' not in line:\n",
        "      line_split = line.split()\n",
        "      line = '\\t'.join(line_split)+'\\n'\n",
        "      #print(line)\n",
        "      newopen.write(line)\n",
        "newopen.close()\n",
        "\n",
        "\n",
        "input_file_path = 'result2_final_tmpSD.txt'\n",
        "output_file_path = 'result2_finalSD.txt'\n",
        "\n",
        "# Read the file and filter out empty lines\n",
        "with open(input_file_path, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "    non_empty_lines = [line.strip() for line in lines if line.strip()]\n",
        "\n",
        "# Write non-empty lines back to the file\n",
        "with open(output_file_path, 'w') as file:\n",
        "    file.write('\\n'.join(non_empty_lines))\n",
        "\n",
        "import os\n",
        "os.remove(input_file_path)\n",
        "os.remove('result2_tmpSD.txt')\n",
        "\n",
        "\n",
        "print(\"completed SD\")"
      ],
      "metadata": {
        "id": "a9APeDZ6oXi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Estrazione OX"
      ],
      "metadata": {
        "id": "FhSzR_aNyWkf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#file_in = open(\"summary.txt\", \"r\")\n",
        "file_in = open(fn,\"r\")\n",
        "outFile = open(\"result2_tmpOx.txt\", \"w\")\n",
        "\n",
        "lines = file_in.readlines()\n",
        "\n",
        "for i, line in enumerate(lines):\n",
        "    # Just a spacing line\n",
        "    #line_sp = line.split()\n",
        "    #print(line_sp)\n",
        "    line_s = line.split(\"\\t\")\n",
        "    #line_s.index\n",
        "    #print(\"line_s1\",line_s)\n",
        "    if line_s:\n",
        "        try:\n",
        "            if(line_s[2] == \"Comment :\"):\n",
        "                #print(\"line_s[2]\",line_s[2])\n",
        "                # Keep track of the comment value\n",
        "                comm = line_s[3]\n",
        "                # Just a spacing line\n",
        "                #print(\"comm\",comm)\n",
        "        except IndexError:\n",
        "            pass\n",
        "        #print(\"line_s[0]\",line_s[2])\n",
        "        #print(\"line \",line)\n",
        "        if len(line_s) == 1:\n",
        "          pass\n",
        "        else:\n",
        "          if(line_s[1] == \"El.\"):\n",
        "            #print(\"lines[i][:-1] \",lines[i][:-1])\n",
        "            #print(\"ID {0} Comment\".format(lines[i][:-1]))\n",
        "            outFile.write(\"ID {0} Comment\\n\".format(lines[i][:-1]))\n",
        "            for j in range(1,loop-1): #loop+1 perch√® non estrae un elemento\n",
        "              #print(\"{0} {1}\\n\".format(lines[i+j][:-1], comm), end=\"\")\n",
        "              outFile.write(\"{0} {1}\\n\".format(lines[i+j][:-1], comm))\n",
        "              #outFile.write(\" {0}\\n\".format(lines))\n",
        "\n",
        "file_in.close()\n",
        "outFile.close() #result2.txt\n",
        "\n",
        "print(\"completed OX extraction\")"
      ],
      "metadata": {
        "id": "pfgKP1LU0dk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#RESULT3 con spazi e tab corretti OX\n",
        "newopen = open(\"result2_finalTmpOx.txt\", \"w\")\n",
        "with open(\"result2_tmpOx.txt\") as f:\n",
        "  first_line = f.readline()\n",
        "  first_line_split = first_line.split()\n",
        "  first_line = '\\t'.join(first_line_split)+'\\n'\n",
        "  newopen.write(first_line)\n",
        "  #print(first_line)\n",
        "\n",
        "with open(\"result2_tmpOx.txt\") as f:\n",
        "  for line in f:\n",
        "    if 'ID Element\tEl.' not in line:\n",
        "      line_split = line.split()\n",
        "      line = '\\t'.join(line_split)+'\\n'\n",
        "      #print(line)\n",
        "      newopen.write(line)\n",
        "newopen.close()\n",
        "\n",
        "input_file_path = 'result2_finalTmpOx.txt'\n",
        "output_file_path = 'result2_finalOx.txt'\n",
        "\n",
        "# Read the file and filter out empty lines\n",
        "with open(input_file_path, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "    non_empty_lines = [line.strip() for line in lines if line.strip()]\n",
        "\n",
        "# Write non-empty lines back to the file\n",
        "with open(output_file_path, 'w') as file:\n",
        "    file.write('\\n'.join(non_empty_lines))\n",
        "\n",
        "os.remove(input_file_path)\n",
        "os.remove('result2_tmpOx.txt')\n",
        "\n",
        "print(\"completed OX\")"
      ],
      "metadata": {
        "id": "BsAszU7qBeB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RESULT3.TXT con dati estratti di SD e DL"
      ],
      "metadata": {
        "id": "XkCr4ykTrOwd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract X-Y coordinates"
      ],
      "metadata": {
        "id": "af8Li3FE9rfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# EXTRACT X and Y coodinates\n",
        "file_in2 = open(fn, \"r\")\n",
        "lines = file_in2.readlines()\n",
        "names = []\n",
        "Xs = []\n",
        "Ys = []\n",
        "Zs = []\n",
        "\n",
        "for i, line in enumerate(lines):\n",
        "    line_s = line.split()\n",
        "    #print(line_s)\n",
        "    if line_s:\n",
        "        try:\n",
        "            if(line_s[4] == \"Comment\"):\n",
        "                # Keep track of the comment value\n",
        "                name = line_s[6]\n",
        "                names.append(name)\n",
        "                # Just a spacing line\n",
        "            elif(line_s[0] == \"Stage\"):\n",
        "                # Keep track of the comment value\n",
        "                x = line_s[3]\n",
        "                Xs.append(x)\n",
        "                y = line_s[5]\n",
        "                Ys.append(y)\n",
        "                z = line_s[7]\n",
        "                Zs.append(z)\n",
        "                # Just a spacing line\n",
        "        except IndexError:\n",
        "            pass\n",
        "\n",
        "import pandas as pd\n",
        "# Just a spacing line\n",
        "print(\"Sample: \",len(names))\n",
        "print(\"X: \", len(Xs))\n",
        "print(\"Y: \", len(Ys))\n",
        "print(\"Z: \", len(Zs))\n",
        "out = pd.DataFrame(\n",
        "    {'Sample': names,\n",
        "     'X':Xs,\n",
        "     'Y':Ys,\n",
        "     'Z':Zs\n",
        "     })\n",
        "# Just a spacing line\n",
        "#print(out)\n",
        "out.to_csv('coordinate.csv', index=False)"
      ],
      "metadata": {
        "id": "faWDjUR_sZ_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "COORDINATE.CSV con sample name e coordinate X e Y"
      ],
      "metadata": {
        "id": "wtj4NXthrYcf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TUTTO DA **SCARICARE**"
      ],
      "metadata": {
        "id": "1uC6qsferhUc"
      }
    }
  ]
}